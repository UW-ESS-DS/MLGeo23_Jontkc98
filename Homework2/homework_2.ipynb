{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "This homework focuses on **resampling** and **noise**.\n",
    "\n",
    "This homework will explore linear regression and resampling techniques by analysing data from a database of glaciers. The database is *Glatilda* for [*Glacier Ice Thickness Database*](https://www.gtn-g.ch/data_catalogue_glathida/).\n",
    "\n",
    "1. Data Statistics\n",
    "2. Data prep (5 points)\n",
    "2. Mapping (10 points)\n",
    "3. Correlations between parameters (5 points)\n",
    "4. Linear regression and resampling techniques (10 points)\n",
    "\n",
    "## 1. Data Prep (5 points total)\n",
    "\n",
    "### a) Download data (1 point) \n",
    "The database is saved on a GitLab repository that you may clone: https://gitlab.com/wgms/glathida.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'glathida'...\n",
      "Checking out files: 100% (61/61), done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer\n",
    "# os.system('git clone git@gitlab.com:wgms/glathida.git')\n",
    "# os.system('git clone https://gitlab.com/wgms/glathida.git')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Import Python modules (1 point) \n",
    "Import pandas, geopandas, plotting, raster files,  numpy, netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import netCDF4 as cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Read data (2 points)\n",
    "Read the glacier data from the file ``glathida/data/glacier.csv`` into a pandas data frame, and decribe briefly the dataframe content and its first few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>name</th>\n",
       "      <th>external_db</th>\n",
       "      <th>external_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>area</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_thickness</th>\n",
       "      <th>mean_thickness_uncertainty</th>\n",
       "      <th>max_thickness</th>\n",
       "      <th>max_thickness_uncertainty</th>\n",
       "      <th>number_points</th>\n",
       "      <th>number_profiles</th>\n",
       "      <th>length_profiles</th>\n",
       "      <th>interpolation_method</th>\n",
       "      <th>flag</th>\n",
       "      <th>remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Isfallsglaciären</td>\n",
       "      <td>WGI</td>\n",
       "      <td>SE4B000E0006</td>\n",
       "      <td>67.91500</td>\n",
       "      <td>18.56800</td>\n",
       "      <td>1979-03-01</td>\n",
       "      <td>1979-03-31</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Rabots glaciär</td>\n",
       "      <td>WGI</td>\n",
       "      <td>SE4B000E1016</td>\n",
       "      <td>67.91000</td>\n",
       "      <td>18.49600</td>\n",
       "      <td>1979-03-01</td>\n",
       "      <td>1979-03-31</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Storglaciären</td>\n",
       "      <td>WGI</td>\n",
       "      <td>SE4B000E0005</td>\n",
       "      <td>67.90000</td>\n",
       "      <td>18.57000</td>\n",
       "      <td>1979-03-01</td>\n",
       "      <td>1979-03-31</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>South Cascade Glacier</td>\n",
       "      <td>WGI</td>\n",
       "      <td>US2M00264006</td>\n",
       "      <td>48.35698</td>\n",
       "      <td>-121.05735</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>1975-12-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Athabasca Glacier</td>\n",
       "      <td>FOG</td>\n",
       "      <td>7</td>\n",
       "      <td>52.17540</td>\n",
       "      <td>-117.28400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  survey_id                   name external_db   external_id  latitude  \\\n",
       "0   1          1       Isfallsglaciären         WGI  SE4B000E0006  67.91500   \n",
       "1   2          1         Rabots glaciär         WGI  SE4B000E1016  67.91000   \n",
       "2   3          1          Storglaciären         WGI  SE4B000E0005  67.90000   \n",
       "3   4          2  South Cascade Glacier         WGI  US2M00264006  48.35698   \n",
       "4   5          3      Athabasca Glacier         FOG             7  52.17540   \n",
       "\n",
       "   longitude        date    max_date  area  ...  mean_thickness  \\\n",
       "0   18.56800  1979-03-01  1979-03-31   1.3  ...            72.0   \n",
       "1   18.49600  1979-03-01  1979-03-31   4.1  ...            84.0   \n",
       "2   18.57000  1979-03-01  1979-03-31   3.1  ...            99.0   \n",
       "3 -121.05735  1975-01-01  1975-12-31   2.0  ...            99.0   \n",
       "4 -117.28400         NaN         NaN   3.8  ...           150.0   \n",
       "\n",
       "   mean_thickness_uncertainty  max_thickness  max_thickness_uncertainty  \\\n",
       "0                         NaN          220.0                        NaN   \n",
       "1                         NaN          175.0                        NaN   \n",
       "2                         NaN          250.0                        NaN   \n",
       "3                         NaN          195.0                        NaN   \n",
       "4                         NaN            NaN                        NaN   \n",
       "\n",
       "   number_points  number_profiles  length_profiles  interpolation_method flag  \\\n",
       "0            NaN              NaN              NaN                   NaN  NaN   \n",
       "1            NaN             10.0              NaN                   NaN  NaN   \n",
       "2            NaN              NaN              NaN                   NaN  NaN   \n",
       "3            NaN              NaN              NaN                   NaN  NaN   \n",
       "4            NaN              NaN              NaN                   NaN  NaN   \n",
       "\n",
       "  remarks  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "t_path = \"glacier.csv\"\n",
    "df = pd.read_csv(t_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: Glacier Thickness Database (GlaThiDa)    \n",
    "Repository URL: https://gitlab.com/wgms/glathida    \n",
    "Accessed on: October 30, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the data with visualization**\n",
    "Before making any inference of models with the data, we will start by exploring basic correlations among parameters by plotting. In particular, we will focus on ``mean_thickness``, ``area``, ``mean_slope`` parameters.\n",
    "\n",
    "### d) Remove bad data (1 point)\n",
    "\n",
    "The database may contain Nans and other \"bad\" values (welcome to the data world!). First we will clean the data by removing nans. We are mostly interested in the thickness, area, and slope\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>area</th>\n",
       "      <th>mean_thickness</th>\n",
       "      <th>mean_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.91500</td>\n",
       "      <td>18.56800</td>\n",
       "      <td>1.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.91000</td>\n",
       "      <td>18.49600</td>\n",
       "      <td>4.1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.90000</td>\n",
       "      <td>18.57000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.35698</td>\n",
       "      <td>-121.05735</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.17540</td>\n",
       "      <td>-117.28400</td>\n",
       "      <td>3.8</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude  area  mean_thickness  mean_slope\n",
       "0  67.91500   18.56800   1.3            72.0         NaN\n",
       "1  67.91000   18.49600   4.1            84.0         NaN\n",
       "2  67.90000   18.57000   3.1            99.0         NaN\n",
       "3  48.35698 -121.05735   2.0            99.0         NaN\n",
       "4  52.17540 -117.28400   3.8           150.0         NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#answer below \n",
    "df = df[['latitude', 'longitude', 'area', 'mean_thickness', 'mean_slope']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mapping glaciers (10 points)\n",
    "\n",
    "Make a global map of the glaciers. Use either of the tools we learned in class:\n",
    "* Geopandas, DEMs from NetCDFfiles (see chapter 2.4)\n",
    "* Pandas and Plotly (see chapter 2.2). You may need to transform some of the series into log-spaced values for better visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Tif and matplotlib\n",
    "\n",
    "You can use the ``elevation`` data from the DEM seen in class. Download the DEM file (https://www.dropbox.com/s/j5lxhd8uxrtsxko/HYP_50M_SR.tif?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___Tips___: when plotting a image in ``matplotlib`` you need to add information about the physical dimensions of the image. You can calculate the ``bounds``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = (elevation.bounds.left, elevation.bounds.right, \\\n",
    "          elevation.bounds.bottom, elevation.bounds.top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ``matplotlib.pyplot`` to show the raster image in the background (tips: use ``imshow()``. The raster image in matplotlib can only import one frame and not three (R, G, B) frames. We will first stack the three images together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = elevation.read(1)\n",
    "green = elevation.read(2)\n",
    "blue = elevation.read(3)\n",
    "pix = np.dstack((red, green, blue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Plotly\n",
    "\n",
    "You may use plotly. For improved visibility, transform some of the data into log-spaced. You may add these transformed Series into the Pandas, and use them as input to plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'vscode' # writes as standalone html, \n",
    "# pio.renderers.default = 'iframe' # writes files as standalone html, \n",
    "# pio.renderers.default = 'png' # writes files as standalone html, \n",
    "# try notebook, jupyterlab, png, vscode, iframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlations between data parameters ( 5 points total)\n",
    "\n",
    "Make plots to vizualise the correlation, or lack of, between all three data. Make at least three plots.\n",
    "\n",
    "### a) Basic correlations using Matplotlib (2 points)\n",
    "\n",
    "Make 3 plots using matplotlib to visualize slope, mean_thickness, and area. Use logscale to see the correlatons.\n",
    "\n",
    "__Tips__: \n",
    "* Use the function ``scatter`` to plot the values of mean thickness, mean slope, area, and latitude. \n",
    "* use one of the dataframe columns as a color using the argument ``c``. You can also vary the ``colormap`` using the argument ``cmap``. Help on colormaps can be found here: https://matplotlib.org/stable/tutorials/colors/colormaps.html. Be mindful of Color-Vision Deficient readers and read *Crameri, F., Shephard, G.E. and Heron, P.J., 2020. The misuse of colour in science communication. Nature communications, 11(1), pp.1-10. https://doi.org/10.1038/s41467-020-19160-7* (find it on the class Gdrive). You can add a third \"data\" by choosing a marker color that scales with an other parameter. For instance, try coloring your marker with the ``LAT`` parameter to look at systematic latitudinal trends from the equator to the poles.\n",
    "* Do not forget to adjust fontsize, figure size (at least 10,8), grid, labels with  of the features (example: km). ou may also explore the *logarithmic* correlations by mapping the axis from linear to logarithmic scale ``plt.xscale('log')``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Mean slope vs mean thickness\n",
    "# solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: area vs mean thickness\n",
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) 3D Scatter plot using Plotly (1 point)\n",
    "\n",
    "Use the plotly ``scatter_3d`` plot. Make sure to change the pandas series for log scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Pandas Correlation function (1 point)\n",
    "\n",
    "You may use Pandas functionalities to explore correlation between data. Use the function ``corr`` on the dataframe and the matplotlib function ``matshow`` to plot a heatmap of the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Seaborn Plotting (1 point)\n",
    "\n",
    "Seaborn is a great python package for basic data anlytics. See documentation [here](!https://seaborn.pydata.org/). You can visualize the data by plotting data features against each other and explore visually data correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the basic correlations among the data. Do these correction make sense when you think about the shapes of glaciers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enter text below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Regression (10 points total counted in the next section)\n",
    "You found from basic data visualization that the three parameters ``mean_slope``, ``mean_thickness``, and ``area`` are correlated. It does make physical sense because a *steep* glaciers is likely to be in the high mountains regions, hanging on the mountain walls, and thus be constrained, and conversely, a flat glacier is either at its valley, ocean terminus or on ice sheets.\n",
    "\n",
    "### a) Simple linear regression (2 points)\n",
    "We will now perform a regression between the parameters (or their log!). Linear regressions are models that can be imported from scikit-learn. Log/exp functions in numpy as ``np.log()`` and ``np.exp()``.\n",
    "Remember that a linear regression is finding $a$ and $b$ knowing both $x$ and the data $y$ in $y = Ax +b$. We want to predict ice thickness from a crude estimate of the glacier area.\n",
    "\n",
    "__Tips__: \n",
    "a. make sure that the dimensions are correct and that there is no NaNs and zeros.\n",
    "b. Make sure to inport the scikit learn linear regression function and the error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot of the data and the linear regression your performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Briefly comment on the quality of your fit and a linear regression (1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit looks pretty good, except that there are outliers on the extreme low and high values of mean area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Leave One Out Cross Validation linear regression (1 point)\n",
    "\n",
    "\n",
    "Perform the LOCCV on the ``area`` and ``thickness`` values. Predict the ``thickness`` value knowing a ``area`` value. Use material seen in class. Make a plot of your fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "# solution\n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Bootstrapping (1 point)\n",
    "\n",
    "Perform the same analysis but using a bootstrapping technique. Output the mean and standard deviation of the slope. An illustration with a histogram  may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# solution\n",
    "\n",
    "k=100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Predict the thickness of a glacier (2 points)\n",
    "\n",
    "Let assume that you measure a glacier of area 10 km$^2$. Can you use your bootstrap regression framework to provide a distribution of possible values of the ice thickness ? Output the mean and standard deviation of the predicted ice thickness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "k=100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c2df93b363d800c8a9b94963221f1be1d8deaf6a76f83b6b9a486ad05d69583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
